RESULTS REPORT
Model: BERT
Encoder: bert-base-uncased
Evaluation: test set (many random seeds)
Train scheme: fine-tuning
Batch size: 16
Dropout rate: 0.1
Learning rate: 1e-05
Adam Epsilon: 1e-08
LR warmup: True
Use MLP: False
Use Normalization layer: False
Weight decay: 0.001
Train time: 11h27m10s
GPU name: Quadro RTX 6000
GPU memory: 22.17

Averages:
Epoch Train loss    std    Test loss    std    Precision  P std   Recall  R std     F1    F1 std
   1   0.385793   0.001140  0.365591  0.010942   0.6471   0.0393  0.5476  0.0383  0.5909  0.0114
   2   0.354466   0.001894  0.386658  0.010731   0.6809   0.0359  0.4216  0.0415  0.5181  0.0239
   3   0.351730   0.001851  0.398950  0.015527   0.6686   0.0318  0.4282  0.0611  0.5176  0.0365
   4   0.335606   0.001285  0.402824  0.003095   0.6413   0.0088  0.4758  0.0168  0.5460  0.0084

*** Detailed report ***

Confusion matrices
------------------
Facts: 0 
Other: 1 
=> Iteration 0:
Epoch 1:
[[ 841  854]
 [ 340 6011]]
Epoch 2:
[[ 650 1045]
 [ 247 6104]]
Epoch 3:
[[ 593 1102]
 [ 238 6113]]
Epoch 4:
[[ 829  866]
 [ 475 5876]]
=> Iteration 1:
Epoch 1:
[[1015  680]
 [ 708 5643]]
Epoch 2:
[[ 614 1081]
 [ 247 6104]]
Epoch 3:
[[ 732  963]
 [ 368 5983]]
Epoch 4:
[[ 769  926]
 [ 405 5946]]
=> Iteration 2:
Epoch 1:
[[ 982  713]
 [ 560 5791]]
Epoch 2:
[[ 748  947]
 [ 341 6010]]
Epoch 3:
[[ 626 1069]
 [ 275 6076]]
Epoch 4:
[[ 776  919]
 [ 428 5923]]
=> Iteration 3:
Epoch 1:
[[ 873  822]
 [ 480 5871]]
Epoch 2:
[[ 763  932]
 [ 443 5908]]
Epoch 3:
[[ 852  843]
 [ 484 5867]]
Epoch 4:
[[ 819  876]
 [ 456 5895]]
=> Iteration 4:
Epoch 1:
[[ 930  765]
 [ 496 5855]]
Epoch 2:
[[ 798  897]
 [ 435 5916]]
Epoch 3:
[[ 826  869]
 [ 482 5869]]
Epoch 4:
[[ 839  856]
 [ 495 5856]]

Scores
------
Epoch: 1
             Train loss  Test loss  Precision    Recall        F1
Iteration 0    0.385844   0.362755   0.712108  0.496165  0.584840
Iteration 1    0.387108   0.387135   0.589089  0.598820  0.593915
Iteration 2    0.386995   0.358178   0.636835  0.579351  0.606735
Iteration 3    0.384394   0.357987   0.645233  0.515044  0.572835
Iteration 4    0.384625   0.361899   0.652174  0.548673  0.595963

Epoch: 2
             Train loss  Test loss  Precision    Recall        F1
Iteration 0    0.353612   0.406178   0.724638  0.383481  0.501543
Iteration 1    0.356581   0.384723   0.713124  0.362242  0.480438
Iteration 2    0.356808   0.375685   0.686869  0.441298  0.537356
Iteration 3    0.353288   0.388289   0.632670  0.450147  0.526026
Iteration 4    0.352044   0.378416   0.647202  0.470796  0.545082

Epoch: 3
             Train loss  Test loss  Precision    Recall        F1
Iteration 0    0.352371   0.417422   0.713598  0.349853  0.469517
Iteration 1    0.352347   0.374929   0.665455  0.431858  0.523792
Iteration 2    0.354225   0.406416   0.694784  0.369322  0.482280
Iteration 3    0.351092   0.387277   0.637725  0.502655  0.562191
Iteration 4    0.348615   0.408704   0.631498  0.487316  0.550117

Epoch: 4
             Train loss  Test loss  Precision    Recall        F1
Iteration 0    0.334860   0.406400   0.635736  0.489086  0.552851
Iteration 1    0.336263   0.400763   0.655026  0.453687  0.536075
Iteration 2    0.337819   0.402385   0.644518  0.457817  0.535357
Iteration 3    0.334789   0.406164   0.642353  0.483186  0.551515
Iteration 4    0.334299   0.398407   0.628936  0.494985  0.553978

