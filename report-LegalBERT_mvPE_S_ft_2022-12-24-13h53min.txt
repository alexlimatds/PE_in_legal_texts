RESULTS REPORT
Model: LegalBERT_mvPE_S
Encoder: nlpaueb/legal-bert-base-uncased
Evaluation: test set (many random seeds)
Train scheme: fine-tuning
Features combination: sum
Batch size: 16
Dropout rate: 0.1
Learning rate: 1e-05
mvPE step: 3000
Max sentence length: 512
Adam Epsilon: 1e-08
LR warmup: True
Use MLP: False
Use Normalization layer: False
Weight decay: 0.001
Train time: 11h33m26s
GPU name: Quadro RTX 6000
GPU memory: 22.17

Averages:
Epoch Train loss    std    Test loss    std    Precision  P std   Recall  R std     F1    F1 std
   1   0.503796   0.011475  0.446624  0.016997   0.5766   0.0336  0.5524  0.0483  0.5613  0.0098
   2   0.449245   0.005699  0.454040  0.011968   0.5809   0.0347  0.4492  0.0732  0.5007  0.0315
   3   0.436432   0.005677  0.451773  0.015425   0.6078   0.0428  0.4571  0.0729  0.5154  0.0347
   4   0.412415   0.005661  0.449825  0.007618   0.6022   0.0052  0.4960  0.0178  0.5438  0.0104

*** Detailed report ***

Confusion matrices
------------------
Facts: 0 
Other: 1 
=> Iteration 0:
Epoch 1:
[[ 846  849]
 [ 524 5827]]
Epoch 2:
[[ 685 1010]
 [ 414 5937]]
Epoch 3:
[[ 638 1057]
 [ 329 6022]]
Epoch 4:
[[ 855  840]
 [ 550 5801]]
=> Iteration 1:
Epoch 1:
[[ 978  717]
 [ 790 5561]]
Epoch 2:
[[ 609 1086]
 [ 389 5962]]
Epoch 3:
[[ 787  908]
 [ 607 5744]]
Epoch 4:
[[ 860  835]
 [ 583 5768]]
=> Iteration 2:
Epoch 1:
[[1049  646]
 [ 899 5452]]
Epoch 2:
[[ 751  944]
 [ 541 5810]]
Epoch 3:
[[ 638 1057]
 [ 339 6012]]
Epoch 4:
[[ 781  914]
 [ 510 5841]]
=> Iteration 3:
Epoch 1:
[[ 971  724]
 [ 771 5580]]
Epoch 2:
[[ 979  716]
 [ 885 5466]]
Epoch 3:
[[ 858  837]
 [ 562 5789]]
Epoch 4:
[[ 849  846]
 [ 553 5798]]
=> Iteration 4:
Epoch 1:
[[ 838  857]
 [ 521 5830]]
Epoch 2:
[[ 783  912]
 [ 604 5747]]
Epoch 3:
[[ 953  742]
 [ 756 5595]]
Epoch 4:
[[ 859  836]
 [ 582 5769]]

Scores
------
Epoch: 1
             Train loss  Test loss  Precision    Recall        F1
Iteration 0    0.487988   0.422383   0.617518  0.499115  0.552039
Iteration 1    0.517566   0.462122   0.553167  0.576991  0.564828
Iteration 2    0.507052   0.462276   0.538501  0.618879  0.575899
Iteration 3    0.493001   0.456359   0.557405  0.572861  0.565028
Iteration 4    0.513371   0.429981   0.616630  0.494395  0.548788

Epoch: 2
             Train loss  Test loss  Precision    Recall        F1
Iteration 0    0.442823   0.457871   0.623294  0.404130  0.490336
Iteration 1    0.459091   0.470985   0.610220  0.359292  0.452284
Iteration 2    0.451778   0.441926   0.581269  0.443068  0.502846
Iteration 3    0.446144   0.460437   0.525215  0.577581  0.550155
Iteration 4    0.446388   0.438983   0.564528  0.461947  0.508112

Epoch: 3
             Train loss  Test loss  Precision    Recall        F1
Iteration 0    0.431016   0.471138   0.659772  0.376401  0.479339
Iteration 1    0.444508   0.435382   0.564562  0.464307  0.509550
Iteration 2    0.441494   0.467541   0.653019  0.376401  0.477545
Iteration 3    0.434929   0.434600   0.604225  0.506195  0.550883
Iteration 4    0.430213   0.450202   0.557636  0.562242  0.559929

Epoch: 4
             Train loss  Test loss  Precision    Recall        F1
Iteration 0    0.406755   0.442519   0.608541  0.504425  0.551613
Iteration 1    0.418852   0.459686   0.595981  0.507375  0.548120
Iteration 2    0.419733   0.454226   0.604957  0.460767  0.523108
Iteration 3    0.408825   0.453274   0.605563  0.500885  0.548273
Iteration 4    0.407907   0.439420   0.596114  0.506785  0.547832

