RESULTS REPORT
Model: CaseLaw_PE_S
Encoder: zlucia/custom-legalbert
Evaluation: test set (many random seeds)
Train scheme: fine-tuning
Features combination: sum
Batch size: 16
Dropout rate: 0.1
Learning rate: 1e-05
mvPE step: 1
Max sentence length: 512
Adam Epsilon: 1e-08
LR warmup: True
Use MLP: False
Use Normalization layer: False
Weight decay: 0.001
Train time: 11h29m33s
GPU name: Quadro RTX 6000
GPU memory: 22.17

Averages:
Epoch Train loss    std    Test loss    std    Precision  P std   Recall  R std     F1    F1 std
   1   0.389626   0.013032  0.363705  0.014983   0.6486   0.0476  0.6117  0.0696  0.6242  0.0245
   2   0.348929   0.003796  0.377865  0.006742   0.6437   0.0197  0.5727  0.0405  0.6047  0.0169
   3   0.341305   0.003701  0.389928  0.007571   0.6541   0.0070  0.5415  0.0094  0.5924  0.0081
   4   0.319070   0.002553  0.395439  0.005859   0.6594   0.0099  0.5383  0.0087  0.5926  0.0043

*** Detailed report ***

Confusion matrices
------------------
Facts: 0 
Other: 1 
=> Iteration 0:
Epoch 1:
[[ 820  875]
 [ 328 6023]]
Epoch 2:
[[ 869  826]
 [ 409 5942]]
Epoch 3:
[[ 937  758]
 [ 483 5868]]
Epoch 4:
[[ 928  767]
 [ 484 5867]]
=> Iteration 1:
Epoch 1:
[[1111  584]
 [ 657 5694]]
Epoch 2:
[[ 982  713]
 [ 581 5770]]
Epoch 3:
[[ 890  805]
 [ 498 5853]]
Epoch 4:
[[ 909  786]
 [ 496 5855]]
=> Iteration 2:
Epoch 1:
[[1086  609]
 [ 694 5657]]
Epoch 2:
[[1025  670]
 [ 615 5736]]
Epoch 3:
[[ 927  768]
 [ 490 5861]]
Epoch 4:
[[ 915  780]
 [ 483 5868]]
=> Iteration 3:
Epoch 1:
[[1012  683]
 [ 443 5908]]
Epoch 2:
[[1058  637]
 [ 599 5752]]
Epoch 3:
[[ 922  773]
 [ 487 5864]]
Epoch 4:
[[ 924  771]
 [ 473 5878]]
=> Iteration 4:
Epoch 1:
[[1155  540]
 [ 787 5564]]
Epoch 2:
[[ 920  775]
 [ 503 5848]]
Epoch 3:
[[ 913  782]
 [ 469 5882]]
Epoch 4:
[[ 886  809]
 [ 423 5928]]

Scores
------
Epoch: 1
             Train loss  Test loss  Precision    Recall        F1
Iteration 0    0.383509   0.347088   0.714286  0.483776  0.576855
Iteration 1    0.415325   0.359841   0.628394  0.655457  0.641640
Iteration 2    0.383543   0.386120   0.610112  0.640708  0.625036
Iteration 3    0.379467   0.349950   0.695533  0.597050  0.642540
Iteration 4    0.386287   0.375528   0.594748  0.681416  0.635139

Epoch: 2
             Train loss  Test loss  Precision    Recall        F1
Iteration 0    0.343899   0.374530   0.679969  0.512684  0.584595
Iteration 1    0.353847   0.385862   0.628279  0.579351  0.602824
Iteration 2    0.345105   0.381949   0.625000  0.604720  0.614693
Iteration 3    0.350604   0.366518   0.638503  0.624189  0.631265
Iteration 4    0.351192   0.380465   0.646521  0.542773  0.590122

Epoch: 3
             Train loss  Test loss  Precision    Recall        F1
Iteration 0    0.340631   0.377487   0.659859  0.552802  0.601605
Iteration 1    0.345140   0.392950   0.641210  0.525074  0.577360
Iteration 2    0.336658   0.398357   0.654199  0.546903  0.595758
Iteration 3    0.338135   0.385367   0.654365  0.543953  0.594072
Iteration 4    0.345960   0.395481   0.660637  0.538643  0.593435

Epoch: 4
             Train loss  Test loss  Precision    Recall        F1
Iteration 0    0.317694   0.390541   0.657224  0.547493  0.597361
Iteration 1    0.321281   0.398217   0.646975  0.536283  0.586452
Iteration 2    0.318381   0.405459   0.654506  0.539823  0.591659
Iteration 3    0.315439   0.389446   0.661417  0.545133  0.597671
Iteration 4    0.322556   0.393535   0.676853  0.522714  0.589880

