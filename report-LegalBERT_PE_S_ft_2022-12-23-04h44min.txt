RESULTS REPORT
Model: LegalBERT_PE_S
Encoder: nlpaueb/legal-bert-base-uncased
Evaluation: test set (many random seeds)
Train scheme: fine-tuning
Features combination: sum
Batch size: 16
Dropout rate: 0.1
Learning rate: 1e-05
mvPE step: 1
Max sentence length: 512
Adam Epsilon: 1e-08
LR warmup: True
Use MLP: False
Use Normalization layer: False
Weight decay: 0.001
Train time: 11h33m30s
GPU name: Quadro RTX 6000
GPU memory: 22.17

Averages:
Epoch Train loss    std    Test loss    std    Precision  P std   Recall  R std     F1    F1 std
   1   0.397725   0.012890  0.354321  0.006263   0.6694   0.0410  0.5961  0.0681  0.6259  0.0210
   2   0.349542   0.002767  0.377177  0.007292   0.6984   0.0251  0.4904  0.0491  0.5736  0.0287
   3   0.344562   0.002915  0.382174  0.011191   0.6705   0.0164  0.5491  0.0385  0.6025  0.0176
   4   0.327464   0.003627  0.386692  0.005149   0.6751   0.0063  0.5390  0.0157  0.5992  0.0091

*** Detailed report ***

Confusion matrices
------------------
Facts: 0 
Other: 1 
=> Iteration 0:
Epoch 1:
[[ 857  838]
 [ 303 6048]]
Epoch 2:
[[ 834  861]
 [ 358 5993]]
Epoch 3:
[[ 838  857]
 [ 389 5962]]
Epoch 4:
[[ 927  768]
 [ 463 5888]]
=> Iteration 1:
Epoch 1:
[[1181  514]
 [ 719 5632]]
Epoch 2:
[[ 676 1019]
 [ 241 6110]]
Epoch 3:
[[ 968  727]
 [ 481 5870]]
Epoch 4:
[[ 926  769]
 [ 445 5906]]
=> Iteration 2:
Epoch 1:
[[1098  597]
 [ 618 5733]]
Epoch 2:
[[ 844  851]
 [ 343 6008]]
Epoch 3:
[[ 897  798]
 [ 402 5949]]
Epoch 4:
[[ 868  827]
 [ 400 5951]]
=> Iteration 3:
Epoch 1:
[[ 977  718]
 [ 505 5846]]
Epoch 2:
[[ 884  811]
 [ 417 5934]]
Epoch 3:
[[ 920  775]
 [ 457 5894]]
Epoch 4:
[[ 902  793]
 [ 445 5906]]
=> Iteration 4:
Epoch 1:
[[ 939  756]
 [ 427 5924]]
Epoch 2:
[[ 918  777]
 [ 463 5888]]
Epoch 3:
[[1031  664]
 [ 573 5778]]
Epoch 4:
[[ 945  750]
 [ 447 5904]]

Scores
------
Epoch: 1
             Train loss  Test loss  Precision    Recall        F1
Iteration 0    0.382712   0.342400   0.738793  0.505605  0.600350
Iteration 1    0.382918   0.354391   0.621579  0.696755  0.657024
Iteration 2    0.404380   0.359806   0.639860  0.647788  0.643799
Iteration 3    0.403246   0.356155   0.659244  0.576401  0.615046
Iteration 4    0.415371   0.358852   0.687408  0.553982  0.613525

Epoch: 2
             Train loss  Test loss  Precision    Recall        F1
Iteration 0    0.347161   0.378025   0.699664  0.492035  0.577762
Iteration 1    0.346062   0.389932   0.737186  0.398820  0.517611
Iteration 2    0.353731   0.377287   0.711036  0.497935  0.585704
Iteration 3    0.349497   0.368262   0.679477  0.521534  0.590120
Iteration 4    0.351259   0.372380   0.664736  0.541593  0.596879

Epoch: 3
             Train loss  Test loss  Precision    Recall        F1
Iteration 0    0.344281   0.392150   0.682967  0.494395  0.573580
Iteration 1    0.346396   0.362634   0.668047  0.571091  0.615776
Iteration 2    0.348762   0.379092   0.690531  0.529204  0.599198
Iteration 3    0.343246   0.393761   0.668119  0.542773  0.598958
Iteration 4    0.340128   0.383231   0.642768  0.608260  0.625038

Epoch: 4
             Train loss  Test loss  Precision    Recall        F1
Iteration 0    0.325119   0.385447   0.666906  0.546903  0.600972
Iteration 1    0.328469   0.384397   0.675419  0.546313  0.604044
Iteration 2    0.333942   0.390290   0.684543  0.512094  0.585893
Iteration 3    0.326330   0.394171   0.669636  0.532153  0.593031
Iteration 4    0.323461   0.379153   0.678879  0.557522  0.612245

